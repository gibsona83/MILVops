import streamlit as st
import pandas as pd
import os

# ğŸ¨ MILV Branded Colors
MILV_COLORS = ["#003366", "#00509e", "#007acc", "#66a3d2", "#cfe2f3"]

# ---------------------------
# Page Configuration & Header
# ---------------------------
st.set_page_config(page_title="MILV Diagnostic Radiology", layout="wide")
st.title("MILV Diagnostic Radiology")
st.caption("*Excludes mammo and IR modalities*")

# ---------------------------
# ğŸ“¥ Load Data from CSV (No SQLite)
# ---------------------------
@st.cache_data
def load_csv_data():
    """Loads CSV files from the main directory and merges them."""
    csv_files = [f for f in os.listdir(".") if f.endswith(".csv") or f.endswith(".csv.gz")]

    if not csv_files:
        st.error("âŒ No CSV files found in the main directory.")
        return pd.DataFrame()

    df_list = []
    for file in csv_files:
        file_path = os.path.join(".", file)
        try:
            temp_df = pd.read_csv(file_path, nrows=100000, compression="infer")  # Loads compressed & uncompressed CSVs
            temp_df["source_file"] = file  # Track source file
            df_list.append(temp_df)
        except Exception as e:
            st.warning(f"âš ï¸ Skipping {file} due to error: {e}")

    if not df_list:
        st.error("âŒ All CSV files are empty or invalid.")
        return pd.DataFrame()

    # Standardize column names
    for df in df_list:
        df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")

    # Expected Columns (Based on Your CSV Structure)
    expected_columns = ["finalizing_provider", "total_exams", "total_rvu", "total_points"]

    # Check if required columns exist
    missing_cols = [col for col in expected_columns if col not in df_list[0].columns]
    if missing_cols:
        st.error(f"âŒ Missing required columns: {missing_cols}")
        st.write("ğŸ” Found columns in CSV:", list(df_list[0].columns))
        return pd.DataFrame()

    # Merge only common columns
    merged_df = pd.concat([df[expected_columns] for df in df_list], ignore_index=True)
    return merged_df

df = load_csv_data()

# Allow Manual File Upload
uploaded_file = st.sidebar.file_uploader("ğŸ“‚ Upload CSV File (Optional)", type=["csv", "gz"])
if uploaded_file:
    df = pd.read_csv(uploaded_file, compression="infer")

# Stop execution if no data
if df.empty:
    st.warning("âš ï¸ No data available. Please check your CSV files.")
    st.stop()

# ---------------------------
# Sidebar Filters
# ---------------------------
st.sidebar.image("milv.png", width=250)
st.sidebar.header("ğŸ“Š Filters")

# Provider Filter
provider_options = ["ALL"] + sorted(df["finalizing_provider"].dropna().unique())
selected_providers = st.sidebar.multiselect("ğŸ‘¨â€âš•ï¸ Select Providers", provider_options, default=["ALL"])
if "ALL" not in selected_providers:
    df = df[df["finalizing_provider"].isin(selected_providers)]

# Download CSV
csv_data = df.to_csv(index=False).encode("utf-8")
st.sidebar.download_button(label=f"ğŸ“¥ Download {len(df):,} rows as CSV", data=csv_data, file_name="filtered_data.csv", mime="text/csv")

if df.empty:
    st.warning("No data after applying filters. Adjust filters to see results.")
    st.stop()

# ---------------------------
# Aggregated KPIs Display
# ---------------------------
st.markdown("## ğŸ“Š Aggregated KPIs")
col1, col2, col3 = st.columns(3)
col1.metric("ğŸ“ Total Exams", f"{df['total_exams'].sum():,}")
col2.metric("âš–ï¸ Total RVU", f"{df['total_rvu'].sum():,.2f}")
col3.metric("ğŸ”¢ Total Points", f"{df['total_points'].sum():,.2f}")

# ---------------------------
# Pagination for Large Datasets
# ---------------------------
st.markdown("## ğŸ” Data Preview")
page_size = 50  # Show 50 rows per page
num_pages = len(df) // page_size + 1
page = st.slider("ğŸ“– Select Page", 1, num_pages, 1)

start_idx = (page - 1) * page_size
end_idx = start_idx + page_size

st.dataframe(df.iloc[start_idx:end_idx])  # Display paginated data

# ---------------------------
# Deployment Instructions
# ---------------------------
st.markdown(
    """
    ### ğŸ“Œ Deployment Instructions
    1. **Push to GitHub**:
       ```
       git init
       git add .
       git commit -m "Optimized app to only use CSV files"
       git branch -M main
       git remote add origin https://github.com/gibsona83/MILVops.git
       git push -u origin main
       ```
    2. **Deploy on Streamlit Cloud**:
       - Go to **[Streamlit Cloud](https://share.streamlit.io/)**
       - Connect your GitHub repository
       - Set `app.py` as the main entry point.
       - Ensure CSV files are **in the main directory** (or use manual upload).
    """
)
